{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(d2l.DataModule):\n",
    "    def __init__(self, num_train, num_val, num_inputs, batch_size):\n",
    "        self.save_hyperparameters()\n",
    "        n = num_train + num_val\n",
    "        self.X = torch.randn(n, num_inputs)\n",
    "        noise = torch.randn(n, 1) * 0.01\n",
    "        w, b = torch.ones((num_inputs, 1)) * 0.01, 0.05\n",
    "        self.y = torch.matmul(self.X, w) + b + noise\n",
    "\n",
    "    def get_dataloader(self, train):\n",
    "        i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
    "        return self.get_tensorloader([self.X, self.y], train, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_penalty(w):\n",
    "    return (w ** 2).sum() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightDecayScratch(d2l.LinearRegressionScratch):\n",
    "    def __init__(self, num_inputs, lambd, lr, sigma=0.01):\n",
    "        super().__init__(num_inputs, lr, sigma)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def loss(self, y_hat, y):\n",
    "        return (super().loss(y_hat, y) +\n",
    "                self.lambd * l2_penalty(self.w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(num_train=20, num_val=100, num_inputs=200, batch_size=5)\n",
    "trainer = d2l.Trainer(max_epochs=10)\n",
    "\n",
    "def train_scratch(lambd):\n",
    "    model = WeightDecayScratch(num_inputs=200, lambd=lambd, lr=0.01)\n",
    "    model.board.yscale='log'\n",
    "    trainer.fit(model, data)\n",
    "    print('L2 norm of w:', float(l2_penalty(model.w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm of w: 0.010835195891559124\n"
     ]
    }
   ],
   "source": [
    "train_scratch(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm of w: 0.009995278902351856\n"
     ]
    }
   ],
   "source": [
    "train_scratch(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightDecay(d2l.LinearRegression):\n",
    "    def __init__(self, wd, lr):\n",
    "        super().__init__(lr)\n",
    "        self.save_hyperparameters()\n",
    "        self.wd = wd\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD([\n",
    "            {'params': self.net.weight, 'weight_decay': self.wd},\n",
    "            {'params': self.net.bias}], lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm of w: 0.014787954278290272\n"
     ]
    }
   ],
   "source": [
    "model = WeightDecay(wd=3, lr=0.01)\n",
    "model.board.yscale='log'\n",
    "trainer.fit(model, data)\n",
    "\n",
    "print('L2 norm of w:', float(l2_penalty(model.get_w_b()[0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
